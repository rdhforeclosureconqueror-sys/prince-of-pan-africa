from fastapi import APIRouter, UploadFile, File, HTTPException
from openai import OpenAI
import requests
import tempfile
import os
import uuid
from pathlib import Path
from app.config import settings

router = APIRouter()

STATIC_AUDIO_DIR = Path("app/static/audio")
STATIC_AUDIO_DIR.mkdir(parents=True, exist_ok=True)

MUFASA_MODEL = "gpt-4o-mini"
AIVOICE_BASE_URL = settings.AIVOICE_BASE_URL
AIVOICE_API_KEY = settings.AIVOICE_API_KEY
OPENAI_API_KEY = settings.OPENAI_API_KEY

client = OpenAI(api_key=OPENAI_API_KEY)


def aivoice_headers():
    headers = {"Content-Type": "application/json"}
    if AIVOICE_API_KEY:
        headers["X-AIVOICE-KEY"] = AIVOICE_API_KEY
    return headers


def generate_audio_filename(ext="mp3"):
    return STATIC_AUDIO_DIR / f"{uuid.uuid4()}.{ext}"


def save_audio_file(audio_bytes, ext="mp3"):
    filename = generate_audio_filename(ext)
    with open(filename, "wb") as f:
        f.write(audio_bytes)
    return f"/static/audio/{filename.name}"


def openai_response(prompt: str) -> str:
    try:
        completion = client.chat.completions.create(
            model=MUFASA_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are Mufasa, the ancient voice of Pan-African wisdom. "
                        "Speak with majesty, history, and reverence for Africaâ€™s legacy. "
                        "Inspire unity, truth, and learning with every response."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.8,
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Mufasa failed to think: {e}")


@router.get("/ping")
async def ping_mufasa():
    return {"status": "ok", "message": "Mufasa is awake and wise."}


@router.post("/message")
async def generate_openai_response(payload: dict):
    message = payload.get("message", "").strip()
    make_voice = payload.get("voice", False)
    voice_model = payload.get("voice_model", "alloy")

    if not message:
        raise HTTPException(status_code=400, detail="No message provided.")

    ai_text = openai_response(message)
    audio_url = None

    if make_voice:
        try:
            tts_response = requests.post(
                f"{AIVOICE_BASE_URL}/tts",
                json={"text": ai_text, "format": "mp3", "voice": voice_model},
                headers=aivoice_headers(),
                timeout=45,
                stream=True,
            )

            if tts_response.status_code == 200:
                audio_url = save_audio_file(tts_response.content)
            else:
                raise HTTPException(
                    status_code=tts_response.status_code,
                    detail=f"aiVoice TTS failed: {tts_response.text}",
                )

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"TTS service failed: {e}")

    return {
        "reply": ai_text,
        "audio_url": audio_url,
        "voice": voice_model,
        "source": "MufasaKnowledgeBank",
    }


@router.post("/tts")
async def text_to_speech(payload: dict):
    text = payload.get("text", "").strip()
    voice = payload.get("voice_model", "alloy")

    if not text:
        raise HTTPException(status_code=400, detail="No text provided for TTS.")

    try:
        tts_response = requests.post(
            f"{AIVOICE_BASE_URL}/tts",
            json={"text": text, "format": "mp3", "voice": voice},
            headers=aivoice_headers(),
            timeout=45,
            stream=True,
        )

        if tts_response.status_code == 200:
            audio_url = save_audio_file(tts_response.content)
            return {"audio_url": audio_url, "voice": voice}

        raise HTTPException(status_code=500, detail="TTS failed to generate.")

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"TTS failed: {e}")


@router.post("/voice")
async def handle_voice_input(file: UploadFile = File(...)):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as tmp:
            tmp.write(await file.read())
            tmp_path = tmp.name

        with open(tmp_path, "rb") as audio_file:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
            )
        user_text = transcription.text.strip()

        ai_text = openai_response(user_text)

        tts_response = requests.post(
            f"{AIVOICE_BASE_URL}/tts",
            json={"text": ai_text, "format": "mp3", "voice": "alloy"},
            headers=aivoice_headers(),
            timeout=45,
            stream=True,
        )

        audio_url = None
        if tts_response.status_code == 200:
            audio_url = save_audio_file(tts_response.content)
        else:
            raise HTTPException(
                status_code=tts_response.status_code,
                detail="aiVoice TTS request failed",
            )

        os.remove(tmp_path)

        return {
            "user_text": user_text,
            "reply": ai_text,
            "audio_url": audio_url,
            "source": "MufasaVoice",
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Voice chat failed: {e}")
